{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-visualize-center-loss.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "ohFs-uX44uZS"
      },
      "cell_type": "markdown",
      "source": [
        "## Install Pytorch if needed"
      ]
    },
    {
      "metadata": {
        "id": "PdxgTM_R0ln-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "doPtfTAl4uZU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "\n",
        "\n",
        "# from os.path import exists\n",
        "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "# import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "27sASF3IpzfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CenterLoss(nn.Module):\n",
        "    \"\"\"Center loss.\n",
        "    \n",
        "    Reference:\n",
        "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
        "    \n",
        "    Args:\n",
        "        num_classes (int): number of classes.\n",
        "        feat_dim (int): feature dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10, feat_dim=2, use_gpu=True):\n",
        "        super(CenterLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.feat_dim = feat_dim\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "        if self.use_gpu:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
        "        else:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: feature matrix with shape (batch_size, feat_dim).\n",
        "            labels: ground truth labels with shape (batch_size).\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
        "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
        "        distmat.addmm_(1, -2, x, self.centers.t())\n",
        "\n",
        "        classes = torch.arange(self.num_classes).long()\n",
        "        if self.use_gpu: classes = classes.cuda()\n",
        "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
        "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
        "\n",
        "        dist = []\n",
        "        for i in range(batch_size):\n",
        "            value = distmat[i][mask[i]]\n",
        "            value = value.clamp(min=1e-12, max=1e+12) # for numerical stability\n",
        "            dist.append(value)\n",
        "        dist = torch.cat(dist)\n",
        "        loss = dist.mean()\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Cq7PhAqo4uZX"
      },
      "cell_type": "markdown",
      "source": [
        "## Import modules"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-04-23T13:00:45.951502",
          "start_time": "2017-04-23T13:00:44.296636"
        },
        "colab_type": "code",
        "id": "5-jCEYf94uZX",
        "outputId": "f26f0f13-0507-46a2-e6f7-74f7ef68dae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "print(\"Pytorch version:  \" + str(torch.__version__))\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"Use CUDA: \" + str(use_cuda))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch version:  0.4.1\n",
            "Use CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z46xBTdm4uZc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BATCH_SIZE_TEST = 1000\n",
        "EPOCHS = 50\n",
        "LOG_INTERVAL = 10\n",
        "NUM_OF_CLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-04-23T13:00:44.295728",
          "start_time": "2017-04-23T13:00:44.293871"
        },
        "colab_type": "text",
        "collapsed": true,
        "id": "h0FbNgzK4uZp"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset setup"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AtqNFTcA4uZp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=BATCH_SIZE_TEST, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eMSEzd-l4uZf"
      },
      "cell_type": "markdown",
      "source": [
        "## Model setup"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TgKqoF-v4uZg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        krnl_sz=3\n",
        "        strd = 1\n",
        "                    \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=krnl_sz, stride=strd, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=krnl_sz, stride=strd, padding=1)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels=50, out_channels=64, kernel_size=krnl_sz, stride=strd, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=krnl_sz, stride=strd, padding=1)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=krnl_sz, stride=strd, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=krnl_sz, stride=strd, padding=1)\n",
        "\n",
        "        self.prelu_weight = nn.Parameter(torch.Tensor(1).fill_(0.25))\n",
        "\n",
        "        self.fc1 = nn.Linear(3*3*512, 3)\n",
        "#         self.fc2 = nn.Linear(3, 2)\n",
        "        self.fc3 = nn.Linear(3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mp_ks=2\n",
        "        mp_strd=2\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=mp_ks, stride=mp_strd)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.max_pool2d(x, kernel_size=mp_ks, stride=mp_strd)\n",
        "\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.max_pool2d(x, kernel_size=mp_ks, stride=mp_strd)\n",
        "\n",
        "        x = x.view(-1, 3*3*512) # Flatten\n",
        "\n",
        "        features3d = self.fc1(x)\n",
        "#         features2d = self.fc2(features3d)\n",
        "        x = F.prelu(features3d, self.prelu_weight)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x, features3d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "do1bwufYE2PW",
        "outputId": "fc5aac40-49cb-4acc-d920-001f75ed73c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.eval()\n",
        "# model.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(50, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=4608, out_features=3, bias=True)\n",
              "  (fc3): Linear(in_features=3, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c8u0rtrNLwYm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### MODEL TEST RUN\n",
        "# ind = 12\n",
        "# image_tensor, label_tensor = test_loader.dataset[ind]\n",
        "# image_tensor = image_tensor.reshape(1,1,28,28)\n",
        "# image_tensor, label_tensor = image_tensor.to(device), label_tensor.to(device)\n",
        "\n",
        "# prediction, features3d, features2d = model(image_tensor)\n",
        "# prediction = np.argmax(prediction.detach().numpy())\n",
        "# print (\"\\033[92m\" + \"PREDICTION : \" + str(prediction) + \"\\033[0m\")\n",
        "\n",
        "# print(\"features3d:  \" + str(features3d.detach().numpy()))\n",
        "# print(\"features2d:  \" + str(features2d.detach().numpy()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VhwxYNXeLwYp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yrmGMDPdLwYr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nk6nnjwvLwYt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "17zxLDwV4uZj"
      },
      "cell_type": "markdown",
      "source": [
        "## Train setup"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NdQVgFKk4uZl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value.\n",
        "       \n",
        "       Code imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def train(model, criterion_xent, criterion_cent, device, train_loader, optimizer_model, optimizer_centloss, epoch):\n",
        "    xent_losses = AverageMeter()\n",
        "    cent_losses = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        outputs, features = model(data)\n",
        "\n",
        "        weight_cent = 1. # weight for center loss\n",
        " \n",
        "        loss_xent = criterion_xent(outputs, labels)\n",
        "        loss_cent = criterion_cent(features, labels)\n",
        "        loss_cent *= weight_cent\n",
        "        loss = loss_xent + loss_cent\n",
        "        optimizer_model.zero_grad()\n",
        "        optimizer_centloss.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_model.step()\n",
        "        # by doing so, weight_cent would not impact on the learning of centers\n",
        "        for param in criterion_cent.parameters():\n",
        "            param.grad.data *= (1. / weight_cent)\n",
        "        optimizer_centloss.step()\n",
        "        \n",
        "        losses.update(loss.item(), labels.size(0))\n",
        "        xent_losses.update(loss_xent.item(), labels.size(0))\n",
        "        cent_losses.update(loss_cent.item(), labels.size(0))\n",
        "\n",
        "  \n",
        "        \n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, criterion_xent, criterion_cent, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in test_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs,features = model(data)\n",
        "#             test_loss += F.nll_loss(output, labels, reduction='sum').item() # sum up batch loss\n",
        "            \n",
        "            weight_cent = 1. # weight for center loss\n",
        "  \n",
        "            loss_xent = criterion_xent(outputs, labels)\n",
        "            loss_cent = criterion_cent(features, labels)\n",
        "            loss_cent *= weight_cent\n",
        "            test_loss = loss_xent + loss_cent\n",
        "\n",
        "#             test_loss += centerLoss(output, labels, device, features3d)\n",
        "\n",
        "            pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "  \n",
        "#     bp()\n",
        "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "#         test_loss, correct, len(test_loader.dataset),\n",
        "#         100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    print('\\nTest set: Average loss: {}, Accuracy: {}/{} ({}%)\\n'.format(\n",
        "        str(test_loss), str(correct), str(len(test_loader.dataset)),\n",
        "        str(100. * correct / len(test_loader.dataset))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rzz0r5To4uZs"
      },
      "cell_type": "markdown",
      "source": [
        "## Train process"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_GFUR8jN4uZu",
        "outputId": "c8520a3f-539b-4e3c-f072-1e7bead9f957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "cell_type": "code",
      "source": [
        "from pdb import set_trace as bp\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer_model = optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-04, momentum=0.5)\n",
        "\n",
        "criterion_xent = nn.CrossEntropyLoss()\n",
        "criterion_cent = CenterLoss(num_classes=NUM_OF_CLASSES, feat_dim=3, use_gpu=True)\n",
        "optimizer_centloss = torch.optim.SGD(criterion_cent.parameters(), lr=0.5)\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, criterion_xent, criterion_cent, device, train_loader, optimizer_model, optimizer_centloss, epoch)\n",
        "    test(model, criterion_xent, criterion_cent, device, test_loader)\n",
        "\n",
        "torch.save(model.state_dict(),\"mnist_cnn-center-loss.pt\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 5.225343\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.712906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-20:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
            "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 99, in get\n",
            "    if not self._rlock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.425985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-525ce0624726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_xent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_centloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_xent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_cent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1b02507096ae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion_xent, criterion_cent, device, train_loader, optimizer_model, optimizer_centloss, epoch)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss_xent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_xent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss_cent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_cent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mloss_cent\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mweight_cent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_xent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_cent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-dc973c135669>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e+12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for numerical stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S-f_NZgj4uZy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LTBjTbqF59Cl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AXpn-upI7SdT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Download from COLAB\n",
        "# from google.colab import files\n",
        "# files.download('mnist_cnn-center-loss.pt') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kiTGuHn9E2QC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zw33B1uFE2QG"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y29d85vOE2QG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net()\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load(\"mnist_cnn-center-loss.pt\", map_location='cpu'))\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KopZtM73E2QH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hn-YeqKkE2QJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ind = 10\n",
        "\n",
        "image = test_loader.dataset[ind][0].numpy().reshape(28,28)\n",
        "lbl = test_loader.dataset[ind][1].numpy()\n",
        "plt.title('this is  --->   ' + str(lbl))\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "\n",
        "image_tensor, label_tensor = test_loader.dataset[ind]\n",
        "image_tensor = image_tensor.reshape(1,1,28,28)\n",
        "image_tensor, label_tensor = image_tensor.to(device), label_tensor.to(device)\n",
        "\n",
        "prediction, features3d = model(image_tensor)\n",
        "prediction = np.argmax(prediction.cpu().detach().numpy())\n",
        "print (\"\\033[92m\" + \"PREDICTION : \" + str(prediction) + \"\\033[0m\")\n",
        "\n",
        "print(\"features3d:  \" + str(features3d.cpu().detach().numpy()))\n",
        "# print(\"features2d:  \" + str(features2d.cpu().detach().numpy()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "F-Dj57YNE2QL"
      },
      "cell_type": "markdown",
      "source": [
        "-----------"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gomfAScIE2QL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUYfwDNuxcC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f3d_train = []\n",
        "lbls_train = []\n",
        "\n",
        "for i in range(10000):\n",
        "    image_tensor_train, label_tensor_train = train_loader.dataset[i]\n",
        "    image_tensor_train = image_tensor_train.reshape(1,1,28,28)\n",
        "    image_tensor_train, label_tensor_train = image_tensor_train.to(device), label_tensor_train.to(device)\n",
        "\n",
        "    prediction_train, features3d_train = model(image_tensor_train)\n",
        "    f3d_train.append(features3d_train[0].cpu().detach().numpy())\n",
        "\n",
        "    prediction_train = np.argmax(prediction_train.cpu().detach().numpy())    \n",
        "    lbls_train.append(prediction_train)\n",
        "\n",
        "    \n",
        "    \n",
        "feat3d_train = np.array(f3d_train)\n",
        "print(\"3d features train shape\" + str(feat3d_train.shape))\n",
        "lbls_train = np.array(lbls_train)\n",
        "print(\"labels train shape\" + str(lbls_train.shape))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j3Xqn5X3pHGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f3d_test = []\n",
        "lbls_test = []\n",
        "\n",
        "for i in range(10000):\n",
        "    image_tensor_test, label_tensor_test = test_loader.dataset[i]\n",
        "    image_tensor_test = image_tensor_test.reshape(1,1,28,28)\n",
        "    image_tensor_test, label_tensor_test = image_tensor_test.to(device), label_tensor_test.to(device)\n",
        "\n",
        "    prediction_test, features3d_test = model(image_tensor_test)\n",
        "    f3d_test.append(features3d_test[0].cpu().detach().numpy())\n",
        "\n",
        "    prediction_test = np.argmax(prediction_test.cpu().detach().numpy())    \n",
        "    lbls_test.append(prediction_test)\n",
        "\n",
        "    \n",
        "    \n",
        "feat3d_test = np.array(f3d_test)\n",
        "print(\"3d features test shape\" + str(feat3d_test.shape))\n",
        "lbls_test = np.array(lbls_test)\n",
        "print(\"labels test shape\" + str(lbls_test.shape))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9QpDlt3pHGe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize 2d"
      ]
    },
    {
      "metadata": {
        "id": "CsgXVnjupHGe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# f = plt.figure(figsize=(16,9))\n",
        "# c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff', \n",
        "#      '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n",
        "# for i in range(10):\n",
        "#     plt.plot(feat2d[lbls==i,0].flatten(), feat2d[lbls==i,1].flatten(), '.', c=c[i])\n",
        "# plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
        "\n",
        "# plt.grid()\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_igyN4zJmybW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize Train Data 3d"
      ]
    },
    {
      "metadata": {
        "id": "u39mNZ_QmywO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "ax = plt.axes(projection='3d')\n",
        "\n",
        "for i in range(10):\n",
        "    # Data for three-dimensional scattered points\n",
        "    xdata = feat3d_train[lbls_train==i,2].flatten()\n",
        "    ydata = feat3d_train[lbls_train==i,0].flatten()\n",
        "    zdata = feat3d_train[lbls_train==i,1].flatten()\n",
        "    ax.scatter3D(xdata, ydata, zdata);\n",
        "ax.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EH_yZxGCpHGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize Test Data 3d"
      ]
    },
    {
      "metadata": {
        "id": "vYRayHzLpHGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "ax = plt.axes(projection='3d')\n",
        "\n",
        "for i in range(10):\n",
        "    # Data for three-dimensional scattered points\n",
        "    xdata = feat3d_test[lbls_test==i,2].flatten()\n",
        "    ydata = feat3d_test[lbls_test==i,0].flatten()\n",
        "    zdata = feat3d_test[lbls_test==i,1].flatten()\n",
        "    ax.scatter3D(xdata, ydata, zdata);\n",
        "ax.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KlV13VerpHGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}